{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from validation_model import FaceValidateV1\n",
    "from settings import *\n",
    "from avapix.avapix_loss import AvapixLoss\n",
    "import avapix.avapix_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddedFacesDataset(Dataset):\n",
    "    def __init__(self, images, gen_per_image) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.transform = ToTensor()\n",
    "\n",
    "        self.images = images\n",
    "        self.gen_per_image = gen_per_image\n",
    "\n",
    "        self.random_lengths = []\n",
    "        self.curr_image_tensor = None\n",
    "\n",
    "    def __getitem__(self, index) -> Any:\n",
    "        if index % self.gen_per_image == 0:\n",
    "            self.random_lengths = list(range(128))\n",
    "            random.shuffle(self.random_lengths)\n",
    "\n",
    "            curr_image = self.images[index // self.gen_per_image]\n",
    "            self.curr_image_tensor = self.transform(Image.open(curr_image))\n",
    "\n",
    "        curr_rand_len = self.random_lengths.pop()\n",
    "\n",
    "        output_img = utils.generate_input_v1(self.curr_image_tensor,\n",
    "                                             DEFAULT_RANDOM_SEED,\n",
    "                                             curr_rand_len)\n",
    "        \n",
    "        return output_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images) * self.gen_per_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FaceValidateV1.load_state_dict(VALIDATION_MODEL_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
